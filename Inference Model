# Inference
def predict_answer(model, tokenizer, context, question):
    inputs = tokenizer.encode_plus(question, context, return_tensors="pt")
    input_ids = inputs["input_ids"]
    attention_mask = inputs["attention_mask"]
    start_logits, end_logits = model(input_ids=input_ids, attention_mask=attention_mask).values()

    start_index = torch.argmax(start_logits, dim=1).item()
    end_index = torch.argmax(end_logits, dim=1).item()

    answer_tokens = input_ids[0][start_index : end_index + 1]
    answer = tokenizer.decode(answer_tokens)
    return answer
# Example context and question for inferen
context = "Universities in the UAE have initiated reductions on tuition fees for the upcoming academic year. These reductions extend up to 50% "
question = "I need a discount in tuition in UAE"
# Perform inference
answer = predict_answer(model, tokenizer, context, question)
print("Answer:", answer)
